{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1W8Nod-4mT5",
        "outputId": "7db152b4-0f55-4d9e-c224-969cb18da883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 21 02:19:24 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The first step is to download the github repo."
      ],
      "metadata": {
        "id": "Xx7NtdH54rmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Quicksticks-oss/LFAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNWv9SRR4rCH",
        "outputId": "412515c0-d283-44a4-c9d9-5062cfb7dc1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LFAI'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 168 (delta 78), reused 112 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (168/168), 19.80 MiB | 19.69 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/LFAI/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptgt2-KC49cU",
        "outputId": "41c9a6a0-3fa2-43f8-fbc5-580a66200c2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LFAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vsBQOP15AtD",
        "outputId": "beed8f15-64d2-49c6-a1b3-3e9e3313ce80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py\n",
            "       [-h]\n",
            "       --name\n",
            "       NAME\n",
            "       [--epochs EPOCHS]\n",
            "       --dataset\n",
            "       DATASET\n",
            "       [--numlayers NUMLAYERS]\n",
            "       [--hiddensize HIDDENSIZE]\n",
            "       [--contextsize CONTEXTSIZE]\n",
            "       [--batchsize BATCHSIZE]\n",
            "       [--learningrate LEARNINGRATE]\n",
            "       [--half HALF]\n",
            "       [--version VERSION]\n",
            "train.py: error: the following arguments are required: --name, --dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we will download our dataset."
      ],
      "metadata": {
        "id": "yOOd57uG5PnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset"
      ],
      "metadata": {
        "id": "7knlKFfu5TSp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./download_dataset.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fCP_jTu5Z5i",
        "outputId": "bde9c851-3918-46d9-a6ea-f13696e822ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-21 02:21:37--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘dataset/input.txt’\n",
            "\n",
            "\rdataset/input.txt     0%[                    ]       0  --.-KB/s               \rdataset/input.txt   100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-08-21 02:21:37 (54.5 MB/s) - ‘dataset/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finally we will train our model."
      ],
      "metadata": {
        "id": "_JPTNEsy5gXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py --name=\"LFAI-Example-Model\" --batchsize=128 --epochs=6 --hiddensize=256 --dataset=\"dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihy-QIy65r4K",
        "outputId": "927096ab-1cf1-4cd7-abb0-36283aec94de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Loading tokenizer...\n",
            "Creating model...\n",
            "Created model with 3.24M params...\n",
            "Training model...\n",
            "[ epoch: 0, loss: 3.2899:   0% 438/1122371 [00:47<29:21:38, 10.61it/s, training... ] ]"
          ]
        }
      ]
    }
  ]
}